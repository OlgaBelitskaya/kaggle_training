{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Challenge: Cleaning numeric columns\n",
    "\n",
    "[Original Version by Rachael Tatman](https://www.kaggle.com/rtatman/data-cleaning-challenge-cleaning-numeric-columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abb7dfd8-87f7-4d15-9dc1-18b88c204d45",
    "_uuid": "d5852418eef82879b1361c0b4d0dfa24f1e1d97d"
   },
   "source": [
    "Welcome to Day 5 of the 5-Day Data Challenge! (Can you believe it's the last day already?) Today, we're going to be learning how to clean up columns with dates and numbers in them that R doesn’t realize are dates or numbers. In particular, we'll learn how to remove symbols like \"%\" or \"$\", and how to get R to correctly parse dates so you can do things like plot days in order. \n",
    "\n",
    "I'll start by introducing each concept or technique, and then you'll get a chance to apply it with an exercise (look for the **Your turn!** section). Ready? Let's get started!\n",
    "___\n",
    "\n",
    "**Kernel FAQs:**\n",
    "\n",
    "* **How do I get started?**   To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n",
    "\n",
    "* **How do I run the code in this notebook?** Once you fork the notebook, it will open in the notebook editor. From there you can write code in any code cell (the ones with the grey background) and run the code by either 1) clicking in the code cell and then hitting CTRL + ENTER or 2) clicking in the code cell and the clicking on the white \"play\" arrow to the left of the cell. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n",
    "\n",
    "* **How do I save my work?** Any changes you make are saved automatically as you work. You can run all the code in your notebook and save a static version by hitting the blue \"Commit & Run\" button in the upper right hand corner of the editor. \n",
    "\n",
    "* **How can I find my notebook again later?** The easiest way is to go to your user profile (https://www.kaggle.com/replace-this-with-your-username), then click on the \"Kernels\" tab. All of your kernels will be under the \"Your Work\" tab, and all the kernels you've upvoted will be under the \"Favorites\" tab.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6ff87bc5-002f-457f-b446-c28cb58b0f4c",
    "_uuid": "889a6594eead9f44b8c0b75d0cb503a07ca8a734"
   },
   "source": [
    "# Get our environment set up\n",
    "___\n",
    "\n",
    "At this point you know the drill: we need to get our libraries and data all read in and ready to go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d1e2d1b4-1b4d-4d3a-9870-251d65a805bf",
    "_kg_hide-output": true,
    "_uuid": "d4dc7b6af917e19fa69178b0a8a9fbcc41fd2c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_character(),\n",
      "  id = col_integer(),\n",
      "  scrape_id = col_double(),\n",
      "  last_scraped = col_date(format = \"\"),\n",
      "  host_id = col_integer(),\n",
      "  host_since = col_date(format = \"\"),\n",
      "  host_listings_count = col_integer(),\n",
      "  host_total_listings_count = col_integer(),\n",
      "  latitude = col_double(),\n",
      "  longitude = col_double(),\n",
      "  accommodates = col_integer(),\n",
      "  bathrooms = col_double(),\n",
      "  bedrooms = col_integer(),\n",
      "  beds = col_integer(),\n",
      "  square_feet = col_integer(),\n",
      "  guests_included = col_integer(),\n",
      "  minimum_nights = col_integer(),\n",
      "  maximum_nights = col_integer(),\n",
      "  availability_30 = col_integer(),\n",
      "  availability_60 = col_integer(),\n",
      "  availability_90 = col_integer()\n",
      "  # ... with 14 more columns\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  `DRG Definition` = col_character(),\n",
      "  `Provider Id` = col_integer(),\n",
      "  `Provider Name` = col_character(),\n",
      "  `Provider Street Address` = col_character(),\n",
      "  `Provider City` = col_character(),\n",
      "  `Provider State` = col_character(),\n",
      "  `Provider Zip Code` = col_integer(),\n",
      "  `Hospital Referral Region Description` = col_character(),\n",
      "  `Total Discharges` = col_integer(),\n",
      "  `Average Covered Charges` = col_character(),\n",
      "  `Average Total Payments` = col_character(),\n",
      "  `Average Medicare Payments` = col_character()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_integer(),\n",
      "  Date = col_character(),\n",
      "  Time = col_time(format = \"\"),\n",
      "  Location = col_character(),\n",
      "  City = col_character(),\n",
      "  Province = col_character(),\n",
      "  `Women/Children` = col_character(),\n",
      "  `Special Mention (Site)` = col_character(),\n",
      "  Comments = col_character(),\n",
      "  References = col_character(),\n",
      "  Longitude = col_double(),\n",
      "  Latitude = col_double(),\n",
      "  `Temperature(C)` = col_double(),\n",
      "  `Temperature(F)` = col_double()\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_character(),\n",
      "  `S#` = col_integer(),\n",
      "  Fatalities = col_integer(),\n",
      "  Injured = col_integer(),\n",
      "  `Total victims` = col_integer(),\n",
      "  `Policeman Killed` = col_integer(),\n",
      "  Age = col_number(),\n",
      "  `Employeed (Y/N)` = col_integer(),\n",
      "  Latitude = col_double(),\n",
      "  Longitude = col_double()\n",
      ")\n",
      "See spec(...) for full column specifications.\n"
     ]
    }
   ],
   "source": [
    "# libraries we'll need\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "library(IRdisplay)\n",
    "library(repr)\n",
    "\n",
    "# read in the data we'll need\n",
    "listings <- read_csv(\"boston-airbnb-open-data/listings.csv\")\n",
    "hospital_charges <- read_csv(\"inpatient-hospital-charges/inpatientCharges.csv\") %>%\n",
    "    janitor::clean_names() # clean up column names, with clean_names() from the janitor package\n",
    "drone_strikes <- read_csv(\"pakistandroneattacks/PakistanDroneAttacksWithTemp Ver 9 (October 19, 2017).csv\") %>%\n",
    "    janitor::clean_names() # clean up column names\n",
    "# remove the last row (has totals in it)\n",
    "drone_strikes <- drone_strikes[-nrow(drone_strikes),] \n",
    "mass_shootings <- read_csv(\"us-mass-shootings-last-50-years/Mass Shootings Dataset Ver 5.csv\")%>%\n",
    "    janitor::clean_names() # clean up column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "h1, h2, h3 {text-shadow: 4px 4px 4px #aaa;} \n",
       "span {color: black; text-shadow: 4px 4px 4px #aaa;}\n",
       "div.output_prompt {color: darkblue;} \n",
       "div.input_prompt {color: steelblue;} \n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_html(\"<style> \n",
    "h1, h2, h3 {text-shadow: 4px 4px 4px #aaa;} \n",
    "span {color: black; text-shadow: 4px 4px 4px #aaa;}\n",
    "div.output_prompt {color: darkblue;} \n",
    "div.input_prompt {color: steelblue;} \n",
    "</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "53f5b3a6-b06e-463f-b91e-f89168f9e228",
    "_uuid": "14a35bb0946936edb1c3c2aa8dd82fd4341c7ae4"
   },
   "source": [
    "# Removing non-numeric characters\n",
    "___\n",
    "\n",
    "Sometimes you'll get a dataset and find that someone has helpfully added percentage signs, dollar signs or other non-numeric symbols that tell you the units of the data you're working with. While this is great when you're looking at the data, it can lead to problems when you're trying to work with it in R. This is because when you read in a dataframe in R, it makes a guess about what data type each column is by looking at what is in that column. And if it runs in to any characters that aren't numbers in your column, it will play it safe and say that the datatype is \"character\" rather than \"numeric\". This means that in order to actually do any math with that column, you need some way to remove any non-numeric characters.\n",
    "\n",
    "If you have tried to solve this problem in the past, you may have come across people suggesting that you use regular expressions. While I'm a big fan of regular expressions (I use one to get days of the week later on in this kernel), I would *strongly* advise you to steer clear of them in data cleaning unless you have no other choice. Why?\n",
    "\n",
    "* **Regular expressions are brittle.** Since they rely on matching a very specific set of characters in a specific order, if you get new data later that's slightly different, your regular expressions won't work. And if you haven't had to debug regular expressions previously, count yourself lucky: it's a huge pain.\n",
    "* **Regular expressions are hard to write & read.** If you've worked with regular expressions before, you know that they are hard to get right! They're also very hard to read: can you tell what this is supposed at first glance? `^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$`.  (It's [a Roman Numeral finder](https://stackoverflow.com/a/800868/9403317), in case you were wondering.) If something is both hard to write and hard to read that means you and your team will spend more time on it than you need to, especially if there's another option.\n",
    "\n",
    "Instead, the option I'd recommend is `parse_numeric()` from the readr package by Jim Hester. This is one of the things we load in with `library(tidyverse)`. `parse_numeric()` can handle most of the common ways that numbers are presented and neatly tidies up the non-numeric characters and changes the class of the resulting object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "f2b98ca0-cba2-4d6e-a122-13f6cf4f879b",
    "_uuid": "fa4ef548e7bba3381aa378823c78a003d1ab7158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Class before:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'character'"
      ],
      "text/latex": [
       "'character'"
      ],
      "text/markdown": [
       "'character'"
      ],
      "text/plain": [
       "[1] \"character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Class after:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'numeric'"
      ],
      "text/latex": [
       "'numeric'"
      ],
      "text/markdown": [
       "'numeric'"
      ],
      "text/plain": [
       "[1] \"numeric\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>100</li>\n",
       "\t<li>10000</li>\n",
       "\t<li>100</li>\n",
       "\t<li>50</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 100\n",
       "\\item 10000\n",
       "\\item 100\n",
       "\\item 50\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 100\n",
       "2. 10000\n",
       "3. 100\n",
       "4. 50\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   100 10000   100    50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# character vector of numbers\n",
    "to_parse <- c(100, \"10,000\", \"%100\", \"$50\")\n",
    "\n",
    "# check to make sure it's numeric\n",
    "print(\"Class before:\")\n",
    "class(to_parse)\n",
    "\n",
    "# parse numbers\n",
    "parsed_numbers <- parse_number(to_parse)\n",
    "\n",
    "# check class\n",
    "print(\"Class after:\")\n",
    "class(parsed_numbers)\n",
    "\n",
    "# see what it looks like now\n",
    "parsed_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c7aaad1b-5d43-485b-8e8a-7eaecdad8fed",
    "_uuid": "b4caeaa5a82404092397e3c0631b83e6aee9ea36"
   },
   "source": [
    "Of  course, it's easy to use with a toy example, by how well does it extend to real datasets? Pretty well, in my experience! \n",
    "\n",
    "First, I like to pull out all the columns that are \"character\" class and look at them. (I focus on character columns because I don't need to re-parse the numeric columns that were parsed correctly the first time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e719147b-ca43-49f7-a9c9-d9bae82f90b5",
    "_uuid": "18d20909461e912a27c06c92e13a3178ff90b51c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t163065 obs. of  9 variables:\n",
      " $ drg_definition                      : chr  \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" ...\n",
      " $ provider_name                       : chr  \"SOUTHEAST ALABAMA MEDICAL CENTER\" \"MARSHALL MEDICAL CENTER SOUTH\" \"ELIZA COFFEE MEMORIAL HOSPITAL\" \"ST VINCENT'S EAST\" ...\n",
      " $ provider_street_address             : chr  \"1108 ROSS CLARK CIRCLE\" \"2505 U S HIGHWAY 431 NORTH\" \"205 MARENGO STREET\" \"50 MEDICAL PARK EAST DRIVE\" ...\n",
      " $ provider_city                       : chr  \"DOTHAN\" \"BOAZ\" \"FLORENCE\" \"BIRMINGHAM\" ...\n",
      " $ provider_state                      : chr  \"AL\" \"AL\" \"AL\" \"AL\" ...\n",
      " $ hospital_referral_region_description: chr  \"AL - Dothan\" \"AL - Birmingham\" \"AL - Birmingham\" \"AL - Birmingham\" ...\n",
      " $ average_covered_charges             : chr  \"$32963.07\" \"$15131.85\" \"$37560.37\" \"$13998.28\" ...\n",
      " $ average_total_payments              : chr  \"$5777.24\" \"$5787.57\" \"$5434.95\" \"$5417.56\" ...\n",
      " $ average_medicare_payments           : chr  \"$4763.73\" \"$4976.71\" \"$4453.79\" \"$4129.16\" ...\n"
     ]
    }
   ],
   "source": [
    "# get only columns with the data type \"character\" \n",
    "character_columns <- hospital_charges[, sapply(hospital_charges, class) == \"character\"]\n",
    "\n",
    "# look at these columns\n",
    "str(character_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c258411-4077-48a2-bf71-122febbdbecd",
    "_uuid": "2f073152c95e9ce3f178217d4782be6a63d6b912"
   },
   "source": [
    "Looking at these columns, it seems like only the last three have been parsed incorrectly: each of them should actually be numeric. My next step is to select just those columns and parse each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "3f5242ee-c3ce-4da8-8f1b-a16924608d08",
    "_uuid": "8af6227e3be646b73c5428bca2052ac04f62f4a6"
   },
   "outputs": [],
   "source": [
    "# select columns with \"charge\" or \"pay\" in the name\n",
    "money_columns <- character_columns %>%\n",
    "    select(contains(\"charge\"), contains(\"pay\")) \n",
    "\n",
    "# parse each of those columns as numeric using sapply()\n",
    "money_columns_parsed <- sapply(money_columns, parse_number) %>%\n",
    "    as_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d0e3052a-fc06-4e83-88d3-a1f32a2015fc",
    "_uuid": "84540759a200ff676aec1c0109148035a91f3bb2"
   },
   "source": [
    "Finally, I make a new copy of the dataset with the parsed columns. (You may want to avoid making a bunch of copies like this if your dataset is very large, but I like the safety net of not modifying data in place.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "8fa20326-f175-477b-8a7f-9faf11b86d81",
    "_uuid": "3c4c5ffd6569fa401c1f00490bb1e5d5c8284c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t163065 obs. of  11 variables:\n",
      " $ drg_definition                      : chr  \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" \"039 - EXTRACRANIAL PROCEDURES W/O CC/MCC\" ...\n",
      " $ provider_id                         : int  10001 10005 10006 10011 10016 10023 10029 10033 10039 10040 ...\n",
      " $ provider_name                       : chr  \"SOUTHEAST ALABAMA MEDICAL CENTER\" \"MARSHALL MEDICAL CENTER SOUTH\" \"ELIZA COFFEE MEMORIAL HOSPITAL\" \"ST VINCENT'S EAST\" ...\n",
      " $ provider_street_address             : chr  \"1108 ROSS CLARK CIRCLE\" \"2505 U S HIGHWAY 431 NORTH\" \"205 MARENGO STREET\" \"50 MEDICAL PARK EAST DRIVE\" ...\n",
      " $ provider_city                       : chr  \"DOTHAN\" \"BOAZ\" \"FLORENCE\" \"BIRMINGHAM\" ...\n",
      " $ provider_state                      : chr  \"AL\" \"AL\" \"AL\" \"AL\" ...\n",
      " $ provider_zip_code                   : int  36301 35957 35631 35235 35007 36116 36801 35233 35801 35903 ...\n",
      " $ hospital_referral_region_description: chr  \"AL - Dothan\" \"AL - Birmingham\" \"AL - Birmingham\" \"AL - Birmingham\" ...\n",
      " $ average_covered_charges             : num  32963 15132 37560 13998 31633 ...\n",
      " $ average_total_payments              : num  5777 5788 5435 5418 5658 ...\n",
      " $ average_medicare_payments           : num  4764 4977 4454 4129 4851 ...\n",
      " - attr(*, \"spec\")=List of 2\n",
      "  ..$ cols   :List of 12\n",
      "  .. ..$ DRG Definition                      : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Provider Id                         : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_integer\" \"collector\"\n",
      "  .. ..$ Provider Name                       : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Provider Street Address             : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Provider City                       : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Provider State                      : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Provider Zip Code                   : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_integer\" \"collector\"\n",
      "  .. ..$ Hospital Referral Region Description: list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Total Discharges                    : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_integer\" \"collector\"\n",
      "  .. ..$ Average Covered Charges             : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Average Total Payments              : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  .. ..$ Average Medicare Payments           : list()\n",
      "  .. .. ..- attr(*, \"class\")= chr  \"collector_character\" \"collector\"\n",
      "  ..$ default: list()\n",
      "  .. ..- attr(*, \"class\")= chr  \"collector_guess\" \"collector\"\n",
      "  ..- attr(*, \"class\")= chr \"col_spec\"\n"
     ]
    }
   ],
   "source": [
    "# replace columns with their parsed versions\n",
    "hospital_charges_parsed <- hospital_charges %>%\n",
    "    # the next line *removes* the columns we selected earlier\n",
    "    select(-contains(\"charge\"), -contains(\"pay\")) %>%\n",
    "    # add the columns we parsed earlier\n",
    "    bind_cols(money_columns_parsed)\n",
    "\n",
    "# double check that our data types are correct\n",
    "str(hospital_charges_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ed506a4-9764-4b4e-889d-1c0c37260514",
    "_uuid": "60e6391293cea26622d31faaa6731b167296c744"
   },
   "source": [
    "And now our numeric columns are actually numeric! From here you can work with them as you would any other numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "200c7c38-b3da-43f2-89c1-e4da77e9461f",
    "_uuid": "0f40a97a72db9e472975dd4c38c694411fc1276d"
   },
   "source": [
    "## Your turn!\n",
    "___\n",
    "\n",
    "Take a look at the `listings` dataset, which contains information on Airbnb listings. You should find quite a few numeric columns read in as characters that need to be parsed. If you're looking for more of a challenge, there are also some logical columns (with 't' and 'f') that have been parsed as characters. Try parsing them using `parse_logical()`. \n",
    "\n",
    "If you're looking an extra-tough challenge, try writing a function that identifies which numeric columns might have been mis-parsed as characters and attempts to parse them correctly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "544f223f-fc52-4771-ab87-db74853dc222",
    "_uuid": "1630fec8fdc5bff900f2b76feda5c39a110678a1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3585 obs. of  61 variables:\n",
      " $ listing_url                     : chr  \"https://www.airbnb.com/rooms/12147973\" \"https://www.airbnb.com/rooms/3075044\" \"https://www.airbnb.com/rooms/6976\" \"https://www.airbnb.com/rooms/1436513\" ...\n",
      " $ name                            : chr  \"Sunny Bungalow in the City\" \"Charming room in pet friendly apt\" \"Mexican Folk Art Haven in Boston\" \"Spacious Sunny Bedroom Suite in Historic Home\" ...\n",
      " $ summary                         : chr  \"Cozy, sunny, family home.  Master bedroom high ceilings. Deck, garden with hens, beehives & play structure.   S\"| __truncated__ \"Charming and quiet room in a second floor 1910 condo building. The room has a full size bed, darkening curtains\"| __truncated__ \"Come stay with a friendly, middle-aged guy in the safe and quiet Roslindale neighborhood of Boston. You will ha\"| __truncated__ \"Come experience the comforts of home away from home in our fabulous bedroom suite available in Roslindale, a ne\"| __truncated__ ...\n",
      " $ space                           : chr  \"The house has an open and cozy feel at the same time.  The living room has a flat screen TV.  The kitchen has a\"| __truncated__ \"Small but cozy and quite room with a full size bed. Ample street parking.\" \"Come stay with a friendly, middle-aged guy in the safe and quiet Roslindale neighborhood of Boston. You will ha\"| __truncated__ \"Most places you find in Boston are small however our bedroom suite is large. The bedroom has plush down pillows\"| __truncated__ ...\n",
      " $ description                     : chr  \"Cozy, sunny, family home.  Master bedroom high ceilings. Deck, garden with hens, beehives & play structure.   S\"| __truncated__ \"Charming and quiet room in a second floor 1910 condo building. The room has a full size bed, darkening curtains\"| __truncated__ \"Come stay with a friendly, middle-aged guy in the safe and quiet Roslindale neighborhood of Boston. You will ha\"| __truncated__ \"Come experience the comforts of home away from home in our fabulous bedroom suite available in Roslindale, a ne\"| __truncated__ ...\n",
      " $ experiences_offered             : chr  \"none\" \"none\" \"none\" \"none\" ...\n",
      " $ neighborhood_overview           : chr  \"Roslindale is quiet, convenient and friendly.  For Southern food try Redd's in Rozzie.  Italian Delfino's or So\"| __truncated__ \"The room is in Roslindale, a diverse and primarily residential neighborhood of Boston. It's well connected via \"| __truncated__ \"The LOCATION: Roslindale is a safe and diverse Boston neighborhood located between Jamaica Plain and West Roxbu\"| __truncated__ \"Roslindale is a lovely little neighborhood located right in the city of Boston.  Though a part of the actual ci\"| __truncated__ ...\n",
      " $ notes                           : chr  NA \"If you don't have a US cell phone, you can text me using (SENSITIVE CONTENTS HIDDEN).\" \"I am in a scenic part of Boston with a couple big parks nearby, and Jamaica Pond, where you can rent a sail boa\"| __truncated__ \"Please be mindful of the property as it is old and needs to be treated with the love and care you would give to\"| __truncated__ ...\n",
      " $ transit                         : chr  \"The bus stop is 2 blocks away, and frequent. Bus is about a 10 minute ride to the Orange line, forest hills. Th\"| __truncated__ \"Plenty of safe street parking. Bus stops a few hundred feet from home. Buses 35, 36, or 37 will take you to the\"| __truncated__ \"PUBLIC TRANSPORTATION: From the house, quick public transportation to Forest Hills station (Orange Line and Com\"| __truncated__ \"There are buses that stop right in front of the house and down the street. We are a convenient bus ride away fr\"| __truncated__ ...\n",
      " $ access                          : chr  \"You will have access to 2 bedrooms, a living room, kitchen, bathrooms, and yard.\" \"Apt has one more bedroom (which I use) and large living space and kitchen that you can use.  Possibility to do \"| __truncated__ \"I am living in the apartment during your stay, and I work from home, so I'm there most of the time.  Guests are\"| __truncated__ \"The basement has a washer dryer and gym area. There is a smart TV you can use while in the gym.  Your iPhone ca\"| __truncated__ ...\n",
      " $ interaction                     : chr  NA \"If I am at home, I am likely working in my home office, which is a separate room. I can help you settle in and \"| __truncated__ \"ABOUT ME: I'm a laid-back, friendly, unmarried guy. I work from home, spending a lot of time on the computer. I\"| __truncated__ \"We do live in the house therefore might be some interaction.  The house is large so it allows the people within\"| __truncated__ ...\n",
      " $ house_rules                     : chr  \"Clean up and treat the home the way you'd like your home to be treated.  No smoking.\" \"Pet friendly but please confirm with me if the pet you are planning on bringing with you is OK. I have a cute a\"| __truncated__ \"I encourage you to use my kitchen, cooking and laundry facilities. There is no additional charge to use the was\"| __truncated__ \"- The bathroom and house are shared so please respect the privacy of others living in the home.  The sunroom an\"| __truncated__ ...\n",
      " $ thumbnail_url                   : chr  \"https://a2.muscache.com/im/pictures/c0842db1-ee98-4fe8-870b-d1e2af33855d.jpg?aki_policy=small\" \"https://a1.muscache.com/im/pictures/39327812/df0f1aab_original.jpg?aki_policy=small\" \"https://a2.muscache.com/im/pictures/6ae8335d-91e6-4598-b380-3129db624df3.jpg?aki_policy=small\" \"https://a2.muscache.com/im/pictures/39764190-16f9-4726-bf6a-2027ff35865c.jpg?aki_policy=small\" ...\n",
      " $ medium_url                      : chr  \"https://a2.muscache.com/im/pictures/c0842db1-ee98-4fe8-870b-d1e2af33855d.jpg?aki_policy=medium\" \"https://a1.muscache.com/im/pictures/39327812/df0f1aab_original.jpg?aki_policy=medium\" \"https://a2.muscache.com/im/pictures/6ae8335d-91e6-4598-b380-3129db624df3.jpg?aki_policy=medium\" \"https://a2.muscache.com/im/pictures/39764190-16f9-4726-bf6a-2027ff35865c.jpg?aki_policy=medium\" ...\n",
      " $ picture_url                     : chr  \"https://a2.muscache.com/im/pictures/c0842db1-ee98-4fe8-870b-d1e2af33855d.jpg?aki_policy=large\" \"https://a1.muscache.com/im/pictures/39327812/df0f1aab_original.jpg?aki_policy=large\" \"https://a2.muscache.com/im/pictures/6ae8335d-91e6-4598-b380-3129db624df3.jpg?aki_policy=large\" \"https://a2.muscache.com/im/pictures/39764190-16f9-4726-bf6a-2027ff35865c.jpg?aki_policy=large\" ...\n",
      " $ xl_picture_url                  : chr  \"https://a2.muscache.com/im/pictures/c0842db1-ee98-4fe8-870b-d1e2af33855d.jpg?aki_policy=x_large\" \"https://a1.muscache.com/im/pictures/39327812/df0f1aab_original.jpg?aki_policy=x_large\" \"https://a2.muscache.com/im/pictures/6ae8335d-91e6-4598-b380-3129db624df3.jpg?aki_policy=x_large\" \"https://a2.muscache.com/im/pictures/39764190-16f9-4726-bf6a-2027ff35865c.jpg?aki_policy=x_large\" ...\n",
      " $ host_url                        : chr  \"https://www.airbnb.com/users/show/31303940\" \"https://www.airbnb.com/users/show/2572247\" \"https://www.airbnb.com/users/show/16701\" \"https://www.airbnb.com/users/show/6031442\" ...\n",
      " $ host_name                       : chr  \"Virginia\" \"Andrea\" \"Phil\" \"Meghna\" ...\n",
      " $ host_location                   : chr  \"Boston, Massachusetts, United States\" \"Boston, Massachusetts, United States\" \"Boston, Massachusetts, United States\" \"Boston, Massachusetts, United States\" ...\n",
      " $ host_about                      : chr  \"We are country and city connecting in our deck and garden. Enjoy our music room, books and flat screen TV with \"| __truncated__ \"I live in Boston and I like to travel and have travelers staying at my place.\" \"I am a middle-aged, single male with a wide range of interests and creative outlets.  I have traveled frequentl\"| __truncated__ \"My husband and I live on the property.  He’s a lawyer and I work as an hospital administration.  We have an add\"| __truncated__ ...\n",
      " $ host_response_time              : chr  \"N/A\" \"within an hour\" \"within a few hours\" \"within a few hours\" ...\n",
      " $ host_response_rate              : chr  \"N/A\" \"100%\" \"100%\" \"100%\" ...\n",
      " $ host_acceptance_rate            : chr  \"N/A\" \"100%\" \"88%\" \"50%\" ...\n",
      " $ host_is_superhost               : chr  \"f\" \"f\" \"t\" \"f\" ...\n",
      " $ host_thumbnail_url              : chr  \"https://a2.muscache.com/im/pictures/5936fef0-ba16-45bd-ac33-9226137d0763.jpg?aki_policy=profile_small\" \"https://a2.muscache.com/im/users/2572247/profile_pic/1442235897/original.jpg?aki_policy=profile_small\" \"https://a2.muscache.com/im/users/16701/profile_pic/1393434148/original.jpg?aki_policy=profile_small\" \"https://a2.muscache.com/im/pictures/5d430cde-7eb2-4ab7-980a-ef07781cd38c.jpg?aki_policy=profile_small\" ...\n",
      " $ host_picture_url                : chr  \"https://a2.muscache.com/im/pictures/5936fef0-ba16-45bd-ac33-9226137d0763.jpg?aki_policy=profile_x_medium\" \"https://a2.muscache.com/im/users/2572247/profile_pic/1442235897/original.jpg?aki_policy=profile_x_medium\" \"https://a2.muscache.com/im/users/16701/profile_pic/1393434148/original.jpg?aki_policy=profile_x_medium\" \"https://a2.muscache.com/im/pictures/5d430cde-7eb2-4ab7-980a-ef07781cd38c.jpg?aki_policy=profile_x_medium\" ...\n",
      " $ host_neighbourhood              : chr  \"Roslindale\" \"Roslindale\" \"Roslindale\" NA ...\n",
      " $ host_verifications              : chr  \"['email', 'phone', 'facebook', 'reviews']\" \"['email', 'phone', 'facebook', 'linkedin', 'amex', 'reviews', 'jumio']\" \"['email', 'phone', 'reviews', 'jumio']\" \"['email', 'phone', 'reviews']\" ...\n",
      " $ host_has_profile_pic            : chr  \"t\" \"t\" \"t\" \"t\" ...\n",
      " $ host_identity_verified          : chr  \"f\" \"t\" \"t\" \"f\" ...\n",
      " $ street                          : chr  \"Birch Street, Boston, MA 02131, United States\" \"Pinehurst Street, Boston, MA 02131, United States\" \"Ardale St., Boston, MA 02131, United States\" \"Boston, MA, United States\" ...\n",
      " $ neighbourhood                   : chr  \"Roslindale\" \"Roslindale\" \"Roslindale\" NA ...\n",
      " $ neighbourhood_cleansed          : chr  \"Roslindale\" \"Roslindale\" \"Roslindale\" \"Roslindale\" ...\n",
      " $ neighbourhood_group_cleansed    : chr  NA NA NA NA ...\n",
      " $ city                            : chr  \"Boston\" \"Boston\" \"Boston\" \"Boston\" ...\n",
      " $ state                           : chr  \"MA\" \"MA\" \"MA\" \"MA\" ...\n",
      " $ zipcode                         : chr  \"02131\" \"02131\" \"02131\" NA ...\n",
      " $ market                          : chr  \"Boston\" \"Boston\" \"Boston\" \"Boston\" ...\n",
      " $ smart_location                  : chr  \"Boston, MA\" \"Boston, MA\" \"Boston, MA\" \"Boston, MA\" ...\n",
      " $ country_code                    : chr  \"US\" \"US\" \"US\" \"US\" ...\n",
      " $ country                         : chr  \"United States\" \"United States\" \"United States\" \"United States\" ...\n",
      " $ is_location_exact               : chr  \"t\" \"t\" \"t\" \"f\" ...\n",
      " $ property_type                   : chr  \"House\" \"Apartment\" \"Apartment\" \"House\" ...\n",
      " $ room_type                       : chr  \"Entire home/apt\" \"Private room\" \"Private room\" \"Private room\" ...\n",
      " $ bed_type                        : chr  \"Real Bed\" \"Real Bed\" \"Real Bed\" \"Real Bed\" ...\n",
      " $ amenities                       : chr  \"{TV,\\\"Wireless Internet\\\",Kitchen,\\\"Free Parking on Premises\\\",\\\"Pets live on this property\\\",Dog(s),Heating,\\\"\"| __truncated__ \"{TV,Internet,\\\"Wireless Internet\\\",\\\"Air Conditioning\\\",Kitchen,\\\"Pets Allowed\\\",\\\"Pets live on this property\\\"\"| __truncated__ \"{TV,\\\"Cable TV\\\",\\\"Wireless Internet\\\",\\\"Air Conditioning\\\",Kitchen,\\\"Free Parking on Premises\\\",Heating,Washer\"| __truncated__ \"{TV,Internet,\\\"Wireless Internet\\\",\\\"Air Conditioning\\\",Kitchen,\\\"Free Parking on Premises\\\",Gym,Breakfast,\\\"In\"| __truncated__ ...\n",
      " $ price                           : chr  \"$250.00\" \"$65.00\" \"$65.00\" \"$75.00\" ...\n",
      " $ weekly_price                    : chr  NA \"$400.00\" \"$395.00\" NA ...\n",
      " $ monthly_price                   : chr  NA NA \"$1,350.00\" NA ...\n",
      " $ security_deposit                : chr  NA \"$95.00\" NA \"$100.00\" ...\n",
      " $ cleaning_fee                    : chr  \"$35.00\" \"$10.00\" NA \"$50.00\" ...\n",
      " $ extra_people                    : chr  \"$0.00\" \"$0.00\" \"$20.00\" \"$25.00\" ...\n",
      " $ calendar_updated                : chr  \"2 weeks ago\" \"a week ago\" \"5 days ago\" \"a week ago\" ...\n",
      " $ has_availability                : chr  NA NA NA NA ...\n",
      " $ requires_license                : chr  \"f\" \"f\" \"f\" \"f\" ...\n",
      " $ license                         : chr  NA NA NA NA ...\n",
      " $ jurisdiction_names              : chr  NA NA NA NA ...\n",
      " $ instant_bookable                : chr  \"f\" \"t\" \"f\" \"f\" ...\n",
      " $ cancellation_policy             : chr  \"moderate\" \"moderate\" \"moderate\" \"moderate\" ...\n",
      " $ require_guest_profile_picture   : chr  \"f\" \"f\" \"t\" \"f\" ...\n",
      " $ require_guest_phone_verification: chr  \"f\" \"f\" \"f\" \"f\" ...\n"
     ]
    }
   ],
   "source": [
    "# your code here :)\n",
    "# get only columns with the data type \"character\" \n",
    "character_columns_listings <- listings[, sapply(listings, class) == \"character\"]\n",
    "\n",
    "# look at these columns\n",
    "str(character_columns_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3585 obs. of  8 variables:\n",
      " $ host_is_superhost               : logi  FALSE FALSE TRUE FALSE TRUE TRUE ...\n",
      " $ host_has_profile_pic            : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...\n",
      " $ host_identity_verified          : logi  FALSE TRUE TRUE FALSE TRUE TRUE ...\n",
      " $ is_location_exact               : logi  TRUE TRUE TRUE FALSE TRUE TRUE ...\n",
      " $ requires_license                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ require_guest_profile_picture   : logi  FALSE FALSE TRUE FALSE FALSE FALSE ...\n",
      " $ require_guest_phone_verification: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ instant_bookable                : logi  FALSE TRUE FALSE FALSE FALSE FALSE ...\n"
     ]
    }
   ],
   "source": [
    "# select columns with logical values \"f\"/\"t\"\n",
    "logical_columns_listings <- character_columns_listings %>%\n",
    "    select(contains(\"host_is\"), \n",
    "           contains(\"host_has\"), \n",
    "           contains(\"host_identity\"), \n",
    "           contains(\"is_location\"), \n",
    "           contains(\"require\"), \n",
    "           contains(\"bookable\")) \n",
    "\n",
    "# parse each of those columns as logical using sapply()\n",
    "logical_columns_listings_parsed <- sapply(logical_columns_listings, parse_logical) %>%\n",
    "    as_data_frame()\n",
    "str(logical_columns_listings_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns with \"price\", \"extra_people\", \"fee\", \"deposit\" in the name\n",
    "money_columns_listings <- character_columns_listings %>%\n",
    "    select(contains(\"price\"),\n",
    "           contains(\"extra_people\"),\n",
    "           contains(\"fee\"),\n",
    "           contains(\"deposit\")) \n",
    "\n",
    "# parse each of those columns as numeric using sapply()\n",
    "money_columns_listings_parsed <- sapply(money_columns_listings, parse_number) %>%\n",
    "    as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>price</th><th scope=col>weekly_price</th><th scope=col>monthly_price</th><th scope=col>extra_people</th><th scope=col>cleaning_fee</th><th scope=col>security_deposit</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>250 </td><td> NA </td><td>  NA</td><td> 0  </td><td>35  </td><td> NA </td></tr>\n",
       "\t<tr><td> 65 </td><td>400 </td><td>  NA</td><td> 0  </td><td>10  </td><td> 95 </td></tr>\n",
       "\t<tr><td> 65 </td><td>395 </td><td>1350</td><td>20  </td><td>NA  </td><td> NA </td></tr>\n",
       "\t<tr><td> 75 </td><td> NA </td><td>  NA</td><td>25  </td><td>50  </td><td>100 </td></tr>\n",
       "\t<tr><td> 79 </td><td> NA </td><td>  NA</td><td> 0  </td><td>15  </td><td> NA </td></tr>\n",
       "\t<tr><td> 75 </td><td> NA </td><td>  NA</td><td> 0  </td><td>30  </td><td> NA </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " price & weekly\\_price & monthly\\_price & extra\\_people & cleaning\\_fee & security\\_deposit\\\\\n",
       "\\hline\n",
       "\t 250  &  NA  &   NA &  0   & 35   &  NA \\\\\n",
       "\t  65  & 400  &   NA &  0   & 10   &  95 \\\\\n",
       "\t  65  & 395  & 1350 & 20   & NA   &  NA \\\\\n",
       "\t  75  &  NA  &   NA & 25   & 50   & 100 \\\\\n",
       "\t  79  &  NA  &   NA &  0   & 15   &  NA \\\\\n",
       "\t  75  &  NA  &   NA &  0   & 30   &  NA \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "price | weekly_price | monthly_price | extra_people | cleaning_fee | security_deposit | \n",
       "|---|---|---|---|---|---|\n",
       "| 250  |  NA  |   NA |  0   | 35   |  NA  | \n",
       "|  65  | 400  |   NA |  0   | 10   |  95  | \n",
       "|  65  | 395  | 1350 | 20   | NA   |  NA  | \n",
       "|  75  |  NA  |   NA | 25   | 50   | 100  | \n",
       "|  79  |  NA  |   NA |  0   | 15   |  NA  | \n",
       "|  75  |  NA  |   NA |  0   | 30   |  NA  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  price weekly_price monthly_price extra_people cleaning_fee security_deposit\n",
       "1 250    NA            NA           0           35            NA             \n",
       "2  65   400            NA           0           10            95             \n",
       "3  65   395          1350          20           NA            NA             \n",
       "4  75    NA            NA          25           50           100             \n",
       "5  79    NA            NA           0           15            NA             \n",
       "6  75    NA            NA           0           30            NA             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(money_columns_listings_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3585 obs. of  8 variables:\n",
      " $ host_is_superhost               : logi  FALSE FALSE TRUE FALSE TRUE TRUE ...\n",
      " $ host_has_profile_pic            : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...\n",
      " $ host_identity_verified          : logi  FALSE TRUE TRUE FALSE TRUE TRUE ...\n",
      " $ is_location_exact               : logi  TRUE TRUE TRUE FALSE TRUE TRUE ...\n",
      " $ requires_license                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ require_guest_profile_picture   : logi  FALSE FALSE TRUE FALSE FALSE FALSE ...\n",
      " $ require_guest_phone_verification: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ instant_bookable                : logi  FALSE TRUE FALSE FALSE FALSE FALSE ...\n"
     ]
    }
   ],
   "source": [
    "# replace columns with their parsed versions\n",
    "listings_parsed1 <- listings %>%\n",
    "    # the next line *removes* the columns we selected earlier\n",
    "    select(-contains(\"host_is\"),\n",
    "           -contains(\"host_has\"),\n",
    "           -contains(\"host_identity\"),\n",
    "           -contains(\"is_location\"),\n",
    "           -contains(\"require\"),\n",
    "           -contains(\"bookable\")) %>%\n",
    "    # add the columns we parsed earlier\n",
    "    bind_cols(logical_columns_listings_parsed)\n",
    "\n",
    "logical_columns <- listings_parsed1[, sapply(listings_parsed1, class) == \"logical\"]\n",
    "# double check that our data types are correct\n",
    "str(logical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3585 obs. of  11 variables:\n",
      " $ scrape_id        : num  2.02e+13 2.02e+13 2.02e+13 2.02e+13 2.02e+13 ...\n",
      " $ latitude         : num  42.3 42.3 42.3 42.3 42.3 ...\n",
      " $ longitude        : num  -71.1 -71.1 -71.1 -71.1 -71.1 ...\n",
      " $ bathrooms        : num  1.5 1 1 1 1.5 1 1 2 1 1 ...\n",
      " $ reviews_per_month: num  NA 1.3 0.47 1 2.25 1.7 4 2.38 5.36 1.01 ...\n",
      " $ price            : num  250 65 65 75 79 75 100 75 58 229 ...\n",
      " $ weekly_price     : num  NA 400 395 NA NA NA NA NA NA NA ...\n",
      " $ monthly_price    : num  NA NA 1350 NA NA NA NA NA NA NA ...\n",
      " $ extra_people     : num  0 0 20 25 0 0 25 15 0 25 ...\n",
      " $ cleaning_fee     : num  35 10 NA 50 15 30 NA 10 NA 50 ...\n",
      " $ security_deposit : num  NA 95 NA 100 NA NA NA NA NA 200 ...\n"
     ]
    }
   ],
   "source": [
    "# replace columns with their parsed versions\n",
    "listings_parsed2 <- listings_parsed1 %>%\n",
    "    # the next line *removes* the columns we selected earlier\n",
    "    select(-contains(\"price\"),\n",
    "           -contains(\"extra_people\"),\n",
    "           -contains(\"fee\"),\n",
    "           -contains(\"deposit\")) %>%\n",
    "    # add the columns we parsed earlier\n",
    "    bind_cols(money_columns_listings_parsed)\n",
    "\n",
    "numeric_columns <- listings_parsed2[, sapply(listings_parsed2, class) == \"numeric\"]\n",
    "# double check that our data types are correct\n",
    "str(numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "754291f5-6fe7-4989-9039-0e96f1573d61",
    "_uuid": "d5c888a1152a43a6d999228860f3e31dfef12937"
   },
   "source": [
    "# Parsing dates & times\n",
    "___\n",
    "\n",
    "Sometimes you're lucky and your dates will be in a format that R knows how to handle and will be read in and parsed automatically. Sometimes, however, you'll have to let R know that a certain column contains a date and what the format of that date is. This is known as *parsing* a date. I generally use [the lubridate package](https://cran.r-project.org/web/packages/lubridate/index.html) by Vitalie Spinu and co-authors for parsing dates. These are the four functions I use most often to parse dates in different formats:\n",
    "\n",
    "* **mdy()**, for dates that are month, day and then year\n",
    "* **ymd()**, for dates that are year, month and then day\n",
    "*  **dmy()**, for dates that are day, month and then year\n",
    "* **ymd_hms()**, for dates that are year, month, day, hour, minute and finally second\n",
    "\n",
    "Once a date is parsed, you can easily extract parts of it using functions like month() and year() and plot or analyze it like any other numeric variable. You can learn more about parsing dates [here](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html).\n",
    "\n",
    "Now that we've got the basics, let's put them into practice. Here are some of the dates in the date column of the `drone_strikes` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "8a259098-9968-4fbb-8dc4-eab58572e87b",
    "_uuid": "e2fcf2fab3513dc81f64917bc68b12023bd9ce35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Friday, June 18, 2004'</li>\n",
       "\t<li>'Sunday, May 08, 2005'</li>\n",
       "\t<li>'Thursday, December 01, 2005'</li>\n",
       "\t<li>'Friday, January 06, 2006'</li>\n",
       "\t<li>'Friday, January 13, 2006'</li>\n",
       "\t<li>'Monday, October 30, 2006'</li>\n",
       "\t<li>'Friday, April 27, 2007'</li>\n",
       "\t<li>'Tuesday, June 19, 2007'</li>\n",
       "\t<li>'Friday, November 02, 2007'</li>\n",
       "\t<li>'Monday, December 03, 2007'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Friday, June 18, 2004'\n",
       "\\item 'Sunday, May 08, 2005'\n",
       "\\item 'Thursday, December 01, 2005'\n",
       "\\item 'Friday, January 06, 2006'\n",
       "\\item 'Friday, January 13, 2006'\n",
       "\\item 'Monday, October 30, 2006'\n",
       "\\item 'Friday, April 27, 2007'\n",
       "\\item 'Tuesday, June 19, 2007'\n",
       "\\item 'Friday, November 02, 2007'\n",
       "\\item 'Monday, December 03, 2007'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Friday, June 18, 2004'\n",
       "2. 'Sunday, May 08, 2005'\n",
       "3. 'Thursday, December 01, 2005'\n",
       "4. 'Friday, January 06, 2006'\n",
       "5. 'Friday, January 13, 2006'\n",
       "6. 'Monday, October 30, 2006'\n",
       "7. 'Friday, April 27, 2007'\n",
       "8. 'Tuesday, June 19, 2007'\n",
       "9. 'Friday, November 02, 2007'\n",
       "10. 'Monday, December 03, 2007'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Friday, June 18, 2004\"       \"Sunday, May 08, 2005\"       \n",
       " [3] \"Thursday, December 01, 2005\" \"Friday, January 06, 2006\"   \n",
       " [5] \"Friday, January 13, 2006\"    \"Monday, October 30, 2006\"   \n",
       " [7] \"Friday, April 27, 2007\"      \"Tuesday, June 19, 2007\"     \n",
       " [9] \"Friday, November 02, 2007\"   \"Monday, December 03, 2007\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the dates\n",
    "drone_strikes$date[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "916e9b48-c3f3-47b2-8fbf-87771f9dae46",
    "_uuid": "b4d7289af67baf4410fe02264da2af2b91161ff5"
   },
   "source": [
    "So our dates are in the format: day of week, month, day of month, year. Unfortunately, there's no lubridate parsing function for handling the day of the week, so we'll need to strip them. (Don't worry, once our dates are parsed we can get them all back with the `wday()` function.) Here, I've written a function to remove them for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "c3e92053-8b7c-48b6-92f4-72b0b2cdde95",
    "_uuid": "77fc54d10eb5919848146fecd32f2870a0f4fe75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'June 18, 2004'</li>\n",
       "\t<li>'May 08, 2005'</li>\n",
       "\t<li>'December 01, 2005'</li>\n",
       "\t<li>'January 06, 2006'</li>\n",
       "\t<li>'January 13, 2006'</li>\n",
       "\t<li>'October 30, 2006'</li>\n",
       "\t<li>'April 27, 2007'</li>\n",
       "\t<li>'June 19, 2007'</li>\n",
       "\t<li>'November 02, 2007'</li>\n",
       "\t<li>'December 03, 2007'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'June 18, 2004'\n",
       "\\item 'May 08, 2005'\n",
       "\\item 'December 01, 2005'\n",
       "\\item 'January 06, 2006'\n",
       "\\item 'January 13, 2006'\n",
       "\\item 'October 30, 2006'\n",
       "\\item 'April 27, 2007'\n",
       "\\item 'June 19, 2007'\n",
       "\\item 'November 02, 2007'\n",
       "\\item 'December 03, 2007'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'June 18, 2004'\n",
       "2. 'May 08, 2005'\n",
       "3. 'December 01, 2005'\n",
       "4. 'January 06, 2006'\n",
       "5. 'January 13, 2006'\n",
       "6. 'October 30, 2006'\n",
       "7. 'April 27, 2007'\n",
       "8. 'June 19, 2007'\n",
       "9. 'November 02, 2007'\n",
       "10. 'December 03, 2007'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"June 18, 2004\"     \"May 08, 2005\"      \"December 01, 2005\"\n",
       " [4] \"January 06, 2006\"  \"January 13, 2006\"  \"October 30, 2006\" \n",
       " [7] \"April 27, 2007\"    \"June 19, 2007\"     \"November 02, 2007\"\n",
       "[10] \"December 03, 2007\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to remove the day of the week (friday, monday, etc.) & following comma\n",
    "remove_dow <- function(column){\n",
    "    no_dow <- str_replace_all(column, '[A-Za-z]*day, ', '')\n",
    "    return(no_dow)\n",
    "}\n",
    "\n",
    "# test it out\n",
    "remove_dow(drone_strikes$date[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15992e5d-4a6c-477d-9a2f-a5ae1c61f985",
    "_uuid": "6018f217c0cbf6957a4f736e38504ec7df10becc"
   },
   "source": [
    "Now we can use this function to remove our day of the week, then parse the remaining data with the `mdy()` function. If you don't need to remove the days of the week, you can just skip that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "d72c6414-9121-4695-ba5f-5026980fa707",
    "_uuid": "6fd27b788bb6273183f4eb83ad9895b86d231d51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>date</th><th scope=col>date_formatted</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Friday, June 18, 2004      </td><td>2004-06-18                 </td></tr>\n",
       "\t<tr><td>Sunday, May 08, 2005       </td><td>2005-05-08                 </td></tr>\n",
       "\t<tr><td>Thursday, December 01, 2005</td><td>2005-12-01                 </td></tr>\n",
       "\t<tr><td>Friday, January 06, 2006   </td><td>2006-01-06                 </td></tr>\n",
       "\t<tr><td>Friday, January 13, 2006   </td><td>2006-01-13                 </td></tr>\n",
       "\t<tr><td>Monday, October 30, 2006   </td><td>2006-10-30                 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " date & date\\_formatted\\\\\n",
       "\\hline\n",
       "\t Friday, June 18, 2004       & 2004-06-18                 \\\\\n",
       "\t Sunday, May 08, 2005        & 2005-05-08                 \\\\\n",
       "\t Thursday, December 01, 2005 & 2005-12-01                 \\\\\n",
       "\t Friday, January 06, 2006    & 2006-01-06                 \\\\\n",
       "\t Friday, January 13, 2006    & 2006-01-13                 \\\\\n",
       "\t Monday, October 30, 2006    & 2006-10-30                 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "date | date_formatted | \n",
       "|---|---|---|---|---|---|\n",
       "| Friday, June 18, 2004       | 2004-06-18                  | \n",
       "| Sunday, May 08, 2005        | 2005-05-08                  | \n",
       "| Thursday, December 01, 2005 | 2005-12-01                  | \n",
       "| Friday, January 06, 2006    | 2006-01-06                  | \n",
       "| Friday, January 13, 2006    | 2006-01-13                  | \n",
       "| Monday, October 30, 2006    | 2006-10-30                  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  date                        date_formatted\n",
       "1 Friday, June 18, 2004       2004-06-18    \n",
       "2 Sunday, May 08, 2005        2005-05-08    \n",
       "3 Thursday, December 01, 2005 2005-12-01    \n",
       "4 Friday, January 06, 2006    2006-01-06    \n",
       "5 Friday, January 13, 2006    2006-01-13    \n",
       "6 Monday, October 30, 2006    2006-10-30    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tidy up dates & convert them to date format\n",
    "dates <- drone_strikes %>%\n",
    "    select(date) %>% # get the \"date\" column\n",
    "    mutate(date_formatted = remove_dow(date)) %>% # remove the day of the week\n",
    "    mutate(date_formatted = mdy(date_formatted)) # convert to date format\n",
    "\n",
    "# compare before & after formatting\n",
    "head(dates)\n",
    "\n",
    "# add formatted dates to our dataframe\n",
    "drone_strikes$date_formatted <- dates$date_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4b9649dd-86e6-4a66-89f0-a90ea078b03c",
    "_uuid": "e907180aaef4eb8b045034151b3347eaee2e3047"
   },
   "source": [
    "And that's all there is to it! You're now ready to start your time series analysis or easily plot your dates using ggplot.\n",
    "\n",
    "## Your turn!\n",
    "___\n",
    "\n",
    "Correctly parse the \"date\" column from the mass_shootings dataset. Print some of the unconverted & converted dates using the head() function to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b248cb67-c5f6-4628-b2f3-f906053c5043",
    "_uuid": "5fc69db8bb6c2754b3a488cfb991336323dd6646"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>11/5/2017 </td><td>11/1/2017 </td><td>10/18/2017</td><td>10/1/2017 </td><td>6/14/2017 </td><td>6/7/2017  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllll}\n",
       "\t 11/5/2017  & 11/1/2017  & 10/18/2017 & 10/1/2017  & 6/14/2017  & 6/7/2017  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 11/5/2017  | 11/1/2017  | 10/18/2017 | 10/1/2017  | 6/14/2017  | 6/7/2017   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]      [,3]       [,4]      [,5]      [,6]    \n",
       "[1,] 11/5/2017 11/1/2017 10/18/2017 10/1/2017 6/14/2017 6/7/2017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code goes here :)\n",
    "# look at the dates\n",
    "t(head(mass_shootings$date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li><time datetime=\"2017-11-05\">2017-11-05</time></li>\n",
       "\t<li><time datetime=\"2017-11-01\">2017-11-01</time></li>\n",
       "\t<li><time datetime=\"2017-10-18\">2017-10-18</time></li>\n",
       "\t<li><time datetime=\"2017-10-01\">2017-10-01</time></li>\n",
       "\t<li><time datetime=\"2017-06-14\">2017-06-14</time></li>\n",
       "\t<li><time datetime=\"2017-06-07\">2017-06-07</time></li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2017-11-05\n",
       "\\item 2017-11-01\n",
       "\\item 2017-10-18\n",
       "\\item 2017-10-01\n",
       "\\item 2017-06-14\n",
       "\\item 2017-06-07\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2017-11-05\n",
       "2. 2017-11-01\n",
       "3. 2017-10-18\n",
       "4. 2017-10-01\n",
       "5. 2017-06-14\n",
       "6. 2017-06-07\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"2017-11-05\" \"2017-11-01\" \"2017-10-18\" \"2017-10-01\" \"2017-06-14\"\n",
       "[6] \"2017-06-07\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert dates to date format\n",
    "formatted_date <- as.Date(mass_shootings$date, format = \"%m/%d/%Y\")\n",
    "# add formatted dates to our dataframe\n",
    "mass_shootings$formatted_date <- formatted_date\n",
    "# look at the formatted dates\n",
    "t(head(mass_shootings$formatted_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed027f21-50f5-4254-8559-55854700a811",
    "_uuid": "7d7e4b9218ce4c5d9de2f547a1748907ae6bc6b7"
   },
   "source": [
    "# And that's it, you've completed the whole challenge!\n",
    "____\n",
    "\n",
    "Congrats, you've finished the entire 5-Day Challenge on data cleaning with R! I hope you learned lots of helpful tips and tricks that you can apply in your work further down the line. :)\n",
    "\n",
    "If you're looking for more content, try checking out [the other 5-Day Challenges](https://www.kaggle.com/rtatman/list-of-5-day-challenges/) or some of the great content we have on the [Kaggle Learn page](https://www.kaggle.com/learn/overview). If you're looking for more practice with data cleaning specifically, I'd recommend picking a new dataset ([maybe one of these](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=all&filetype=all&license=all&tagids=13202)), getting to know it (mainly doing a lot of visualizations) and then making the changes you need to use it for modelling or analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.4",
   "language": "R",
   "name": "ir34"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
